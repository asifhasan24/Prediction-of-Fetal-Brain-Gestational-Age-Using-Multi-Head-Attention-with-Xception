{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNs8EsNUzq8ER2OIO+1yTXq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asifhasan24/codetest/blob/main/Prediction_of_Fetal_Brain_Gestational_Age_Using_Multi_Head_Attention_with_Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEL8WC1gaR3y"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!pwd\n",
        "!pip install tensorflow-addons\n",
        "!kaggle datasets download -d asifhasan24/fetal-brain\n",
        "!unzip /content/fetal-brain.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, MultiHeadAttention\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the dataset\n",
        "image_folder_path = \"/content/images\"\n",
        "img_size = 75\n",
        "\n",
        "# Define a function to apply unsharp masking to an image\n",
        "def enhance_image(image):\n",
        "    # Apply Unsharp Masking\n",
        "    gaussian_blur = cv2.GaussianBlur(image, (0, 0), 3)\n",
        "    unsharp_image = cv2.addWeighted(image, 1.5, gaussian_blur, -0.8, 0)\n",
        "\n",
        "    return unsharp_image\n",
        "\n",
        "# Create a dictionary that maps each image file name to its label\n",
        "label_dict = {}\n",
        "for subdirectory in os.listdir(image_folder_path):\n",
        "    if os.path.isfile(os.path.join(image_folder_path, subdirectory)):\n",
        "        continue\n",
        "    for image_file in os.listdir(os.path.join(image_folder_path, subdirectory)):\n",
        "        if image_file.endswith(\".jpg\") or image_file.endswith(\".jpeg\") or image_file.endswith(\".png\"):\n",
        "            label_dict[os.path.join(subdirectory, image_file)] = int(subdirectory)\n",
        "\n",
        "# Shuffle the list of images\n",
        "img_list = list(label_dict.keys())\n",
        "random.shuffle(img_list)\n",
        "print(len(img_list))\n",
        "\n",
        "# Split the list of images into training, validation, and testing sets\n",
        "train_images, test_image_list = train_test_split(img_list, test_size=0.3)  # 70% for training\n",
        "val_image_list, test_image_list = train_test_split(test_image_list, test_size=0.67)  # 10% for validation, 20% for testing\n",
        "\n",
        "print(len(train_images))\n",
        "print(len(val_image_list))\n",
        "print(len(test_image_list))\n",
        "\n",
        "# Use the new lists to create training, validation, and test sets\n",
        "train_img, val_img, test_img = [], [], []\n",
        "train_labels, val_labels, test_labels = [], [], []\n",
        "\n",
        "for image_file in train_images:\n",
        "    if image_file in label_dict:\n",
        "        image = cv2.imread(os.path.join(image_folder_path, image_file))\n",
        "        image = image / 255.0\n",
        "        enhanced_image = enhance_image(image)\n",
        "        train_img.append(cv2.resize(enhanced_image, (img_size, img_size)))\n",
        "        train_labels.append(label_dict[image_file])\n",
        "    else:\n",
        "        print(f\"Label not found for image: {image_file}\")\n",
        "\n",
        "for image_file in val_image_list:\n",
        "    if image_file in label_dict:\n",
        "        image = cv2.imread(os.path.join(image_folder_path, image_file))\n",
        "        image = image / 255.0\n",
        "        enhanced_image = enhance_image(image)\n",
        "        val_img.append(cv2.resize(enhanced_image, (img_size, img_size)))\n",
        "        val_labels.append(label_dict[image_file])\n",
        "    else:\n",
        "        print(f\"Label not found for image: {image_file}\")\n",
        "\n",
        "for image_file in test_image_list:\n",
        "    if image_file in label_dict:\n",
        "        image = cv2.imread(os.path.join(image_folder_path, image_file))\n",
        "        image = image / 255.0\n",
        "        enhanced_image = enhance_image(image)\n",
        "        test_img.append(cv2.resize(enhanced_image, (img_size, img_size)))\n",
        "        test_labels.append(label_dict[image_file])\n",
        "    else:\n",
        "        print(f\"Label not found for image: {image_file}\")\n",
        "\n",
        "train_img = np.array(train_img)\n",
        "train_labels = np.array(train_labels)\n",
        "val_img = np.array(val_img)\n",
        "val_labels = np.array(val_labels)\n",
        "test_img = np.array(test_img)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "train_img = preprocess_input(train_img)\n",
        "val_img = preprocess_input(val_img)\n",
        "test_img = preprocess_input(test_img)\n",
        "\n",
        "# Load the Xception model pre-trained on ImageNet data\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
        "\n",
        "# Add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Reshape x to have sequence length dimension\n",
        "x = tf.expand_dims(x, axis=1)  # Shape: (None, 1, 2048)\n",
        "\n",
        "# Add multi-head attention layer\n",
        "num_heads = 8\n",
        "key_dim = 64\n",
        "value_dim = 64\n",
        "attention_output, attention_scores = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, value_dim=value_dim)(x, x, return_attention_scores=True)\n",
        "\n",
        "# Flatten the attention output tensor\n",
        "attention_output = tf.keras.layers.Flatten()(attention_output)\n",
        "\n",
        "# Add a fully-connected layer with 512 hidden units and relu activation\n",
        "x = Dense(512, activation='relu')(attention_output)\n",
        "\n",
        "# Add the output layer with one neuron for regression\n",
        "output_layer = Dense(1)(x)\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "model.compile(loss='mean_squared_error', optimizer=RMSprop(lr=0.001), metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_img, train_labels, epochs=100, batch_size=16, validation_data=(val_img, val_labels))\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred = model.predict(test_img)\n",
        "r2 = r2_score(test_labels, y_pred)\n",
        "mae = mean_absolute_error(test_labels, y_pred)\n",
        "mse = mean_squared_error(test_labels, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Test Set - R-squared score: {:.3f}\".format(r2))\n",
        "print(\"Test Set - MAE: {:.3f}\".format(mae))\n",
        "print(\"Test Set - MSE: {:.3f}\".format(mse))\n",
        "print(\"Test Set - RMSE: {:.3f}\".format(rmse))\n",
        "\n",
        "# Evaluate on the validation set\n",
        "val_pred = model.predict(val_img)\n",
        "val_r2 = r2_score(val_labels, val_pred)\n",
        "val_mae = mean_absolute_error(val_labels, val_pred)\n",
        "val_mse = mean_squared_error(val_labels, val_pred)\n",
        "val_rmse = np.sqrt(val_mse)\n",
        "print(\"Validation Set - R-squared score: {:.3f}\".format(val_r2))\n",
        "print(\"Validation Set - MAE: {:.3f}\".format(val_mae))\n",
        "print(\"Validation Set - MSE: {:.3f}\".format(val_mse))\n",
        "print(\"Validation Set - RMSE: {:.3f}\".format(val_rmse))\n"
      ],
      "metadata": {
        "id": "VuHP4dHgb0SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, MultiHeadAttention\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the dataset\n",
        "image_folder_path = \"/content/images\"\n",
        "img_size = 75\n",
        "\n",
        "# Define a function to apply unsharp masking to an image\n",
        "def enhance_image(image):\n",
        "    # Apply Unsharp Masking\n",
        "    gaussian_blur = cv2.GaussianBlur(image, (0, 0), 3)\n",
        "    unsharp_image = cv2.addWeighted(image, 1.5, gaussian_blur, -0.8, 0)\n",
        "\n",
        "    return unsharp_image\n",
        "\n",
        "# Create a dictionary that maps each image file name to its label\n",
        "label_dict = {}\n",
        "for subdirectory in os.listdir(image_folder_path):\n",
        "    if os.path.isfile(os.path.join(image_folder_path, subdirectory)):\n",
        "        continue\n",
        "    for image_file in os.listdir(os.path.join(image_folder_path, subdirectory)):\n",
        "        if image_file.endswith(\".jpg\") or image_file.endswith(\".jpeg\") or image_file.endswith(\".png\"):\n",
        "            label_dict[os.path.join(subdirectory, image_file)] = int(subdirectory)\n",
        "\n",
        "# Shuffle the list of images\n",
        "img_list = list(label_dict.keys())\n",
        "random.shuffle(img_list)\n",
        "\n",
        "excel_file_path = '/content/images/labels.xlsx'\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "df['cor_series'] = df['cor_series'].astype(str)\n",
        "df['cor_series'] = df['cor_series'].apply(lambda x: x.zfill(4))\n",
        "cor_series_column = df['cor_series']\n",
        "\n",
        "# Filter the image list based on cor_series values\n",
        "filtered_img_list = [image_file for image_file in img_list if any((f\"-{cor_series_value}-\" in image_file) for cor_series_value in cor_series_column)]\n",
        "print(len(filtered_img_list))\n",
        "\n",
        "# Split the list of images into training, validation, and testing sets\n",
        "train_val_images, test_image_list = train_test_split(filtered_img_list, test_size=0.2)\n",
        "train_image_list, val_image_list = train_test_split(train_val_images, test_size=0.125)  # 10% for validation\n",
        "\n",
        "print(len(train_image_list))\n",
        "print(len(val_image_list))\n",
        "print(len(test_image_list))\n",
        "\n",
        "# Create image and label arrays for training, validation, and testing\n",
        "train_img, val_img, test_img = [], [], []\n",
        "train_labels, val_labels, test_labels = [], [], []\n",
        "\n",
        "# Load and preprocess images for training set\n",
        "for image_file in train_image_list:\n",
        "    if image_file in label_dict:\n",
        "        image = cv2.imread(os.path.join(image_folder_path, image_file))\n",
        "        image = image / 255.0\n",
        "        enhanced_image = enhance_image(image)\n",
        "        train_img.append(cv2.resize(enhanced_image, (img_size, img_size)))\n",
        "        train_labels.append(label_dict[image_file])\n",
        "    else:\n",
        "        print(f\"Label not found for image: {image_file}\")\n",
        "\n",
        "# Load and preprocess images for validation set\n",
        "for image_file in val_image_list:\n",
        "    if image_file in label_dict:\n",
        "        image = cv2.imread(os.path.join(image_folder_path, image_file))\n",
        "        image = image / 255.0\n",
        "        enhanced_image = enhance_image(image)\n",
        "        val_img.append(cv2.resize(enhanced_image, (img_size, img_size)))\n",
        "        val_labels.append(label_dict[image_file])\n",
        "    else:\n",
        "        print(f\"Label not found for image: {image_file}\")\n",
        "\n",
        "# Load and preprocess images for test set\n",
        "for image_file in test_image_list:\n",
        "    if image_file in label_dict:\n",
        "        image = cv2.imread(os.path.join(image_folder_path, image_file))\n",
        "        image = image / 255.0\n",
        "        enhanced_image = enhance_image(image)\n",
        "        test_img.append(cv2.resize(enhanced_image, (img_size, img_size)))\n",
        "        test_labels.append(label_dict[image_file])\n",
        "    else:\n",
        "        print(f\"Label not found for image: {image_file}\")\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_img = np.array(train_img)\n",
        "train_labels = np.array(train_labels)\n",
        "val_img = np.array(val_img)\n",
        "val_labels = np.array(val_labels)\n",
        "test_img = np.array(test_img)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Preprocess input images\n",
        "train_img = preprocess_input(train_img)\n",
        "val_img = preprocess_input(val_img)\n",
        "test_img = preprocess_input(test_img)\n",
        "\n",
        "# Load the Xception model pre-trained on ImageNet data\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
        "\n",
        "# Add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Reshape x to have sequence length dimension\n",
        "x = tf.expand_dims(x, axis=1)  # Shape: (None, 1, 2048)\n",
        "\n",
        "# Add multi-head attention layer\n",
        "num_heads = 8\n",
        "key_dim = 64\n",
        "value_dim = 64\n",
        "attention_output, attention_scores = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, value_dim=value_dim)(x, x, return_attention_scores=True)\n",
        "\n",
        "# Flatten the attention output tensor\n",
        "attention_output = tf.keras.layers.Flatten()(attention_output)\n",
        "\n",
        "# Add a fully-connected layer with 512 hidden units and relu activation\n",
        "x = Dense(512, activation='relu')(attention_output)\n",
        "\n",
        "# Add the output layer with one neuron for regression\n",
        "output_layer = Dense(1)(x)\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "model.compile(loss='mean_squared_error', optimizer=RMSprop(lr=0.001), metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_img, train_labels, epochs=100, batch_size=16, validation_data=(val_img, val_labels))\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred = model.predict(test_img)\n",
        "r2 = r2_score(test_labels, y_pred)\n",
        "mae = mean_absolute_error(test_labels, y_pred)\n",
        "mse = mean_squared_error(test_labels, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Test Set - R-squared score: {:.3f}\".format(r2))\n",
        "print(\"Test Set - MAE: {:.3f}\".format(mae))\n",
        "print(\"Test Set - MSE: {:.3f}\".format(mse))\n",
        "print(\"Test Set - RMSE: {:.3f}\".format(rmse))\n",
        "\n",
        "# Evaluate on the validation set\n",
        "val_pred = model.predict(val_img)\n",
        "val_r2 = r2_score(val_labels, val_pred)\n",
        "val_mae = mean_absolute_error(val_labels, val_pred)\n",
        "val_mse = mean_squared_error(val_labels, val_pred)\n",
        "val_rmse = np.sqrt(val_mse)\n",
        "print(\"Validation Set - R-squared score: {:.3f}\".format(val_r2))\n",
        "print(\"Validation Set - MAE: {:.3f}\".format(val_mae))\n",
        "print(\"Validation Set - MSE: {:.3f}\".format(val_mse))\n",
        "print(\"Validation Set - RMSE: {:.3f}\".format(val_rmse))\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/modelcor.h5')\n"
      ],
      "metadata": {
        "id": "ETkgzFA4bwL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the actual vs predicted values for the test set\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(test_labels, y_pred, color='blue', alpha=0.5, label='Actual vs Predicted')\n",
        "plt.title('Actual vs Predicted Values (Test Set)')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CkQPwWD4bm-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C4keKI_Gbs-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}